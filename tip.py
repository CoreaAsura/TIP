import streamlit as st
import requests
from sgp4.api import Satrec, jday
from datetime import datetime, timedelta
import math
import pandas as pd
import os
from pytz import timezone

# ì„œìš¸ ê¸°ì¤€ ì¢Œí‘œ
SEOUL_LAT, SEOUL_LON = 37.5665, 126.9780

# UI ì„¤ì •
st.set_page_config(page_title="ìš°ì£¼ë‚™í•˜ë¬¼ì²´ ë¶„ì„", layout="wide")
st.title("â˜„ï¸ ìš°ì£¼ë‚™í•˜ë¬¼ì²´ í˜„í™© for MSSB")

# ì‹œê°„ ì¶œë ¥ (KST)
kst_now = datetime.utcnow().astimezone(timezone("Asia/Seoul"))
st.markdown(f"ğŸ•’ ìµœê·¼ ì—…ë°ì´íŠ¸ (KST): `{kst_now.strftime('%Y-%m-%d %H:%M:%S')}`")

# ì„¤ì • ìŠ¬ë¼ì´ë”
hours = st.slider("TIP ë¶„ì„ ì‹œê°„ ë²”ìœ„ (ì‹œê°„)", 24, 168, 72)
radius_km = st.slider("ì„œìš¸ ê¸°ì¤€ ë¶„ì„ ë°˜ê²½ (km)", 500, 5000, 3000)

# TLE ì €ì¥ ê²½ë¡œ ë° URL
TLE_FILE = "tle_data.txt"
TLE_URL = "https://celestrak.org/NORAD/elements/gp.php?GROUP=active&FORMAT=TLE"

# TLE ë‹¤ìš´ë¡œë“œ ë° ì €ì¥
if not os.path.exists(TLE_FILE):
    try:
        tle_raw = requests.get(TLE_URL, timeout=10).text
        with open(TLE_FILE, "w", encoding="utf-8") as f:
            f.write(tle_raw)
        st.success("âœ… TLE ë°ì´í„° ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        st.error(f"âŒ TLE ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")

# TLE ì½ê¸°
with open(TLE_FILE, "r", encoding="utf-8") as f:
    lines = f.readlines()

# TLE íŒŒì‹±
tle_sets = []
for i in range(0, len(lines), 3):
    try:
        name = lines[i].strip()
        line1 = lines[i+1].strip()
        line2 = lines[i+2].strip()
        tle_sets.append((name, line1, line2))
    except:
        continue

st.markdown(f"ğŸ“Š ë¶„ì„ ëŒ€ìƒ ìš°ì£¼ë¬¼ì²´ ìˆ˜: `{len(tle_sets)}` ê°œ")

# TLE íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë§í¬
st.download_button("ğŸ“¥ ì „ì²´ TLE ë°ì´í„° ë‹¤ìš´ë¡œë“œ", data=''.join(lines), file_name="tle_data.txt", mime="text/plain")

# ê±°ë¦¬ ê³„ì‚° í•¨ìˆ˜
def haversine(lat1, lon1, lat2, lon2):
    R = 6371
    dLat = math.radians(lat2 - lat1)
    dLon = math.radians(lon2 - lon1)
    a = math.sin(dLat/2)**2 + math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(dLon/2)**2
    return R * 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))

# ê¶¤ë„ ì˜ˆì¸¡ í•¨ìˆ˜
def predict_positions(name, line1, line2, duration_hr):
    sat = Satrec.twoline2rv(line1, line2)
    positions = []
    now = datetime.utcnow()
    for i in range(0, duration_hr * 60, 30):
        dt = now + timedelta(minutes=i)
        jd, fr = jday(dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second)
        e, r, v = sat.sgp4(jd, fr)
        if e == 0:
            x, y, z = r
            altitude = math.sqrt(x**2 + y**2 + z**2) - 6371
            lon = math.degrees(math.atan2(y, x))
            hyp = math.sqrt(x**2 + y**2)
            lat = math.degrees(math.atan2(z, hyp))
            positions.append((dt, altitude, lat, lon))
    return positions

# ë¶„ì„ ìˆ˜í–‰
seoul_objects = []
decaying_objects = []
for name, line1, line2 in tle_sets:
    try:
        sat = Satrec.twoline2rv(line1, line2)
        positions = predict_positions(name, line1, line2, hours)

        # ì„œìš¸ ê¸°ì¤€ ë‚™í•˜ í›„ë³´ íŒë³„
        for dt, alt, lat, lon in positions:
            dist = haversine(SEOUL_LAT, SEOUL_LON, lat, lon)
            if dist <= radius_km and alt < 200:
                seoul_objects.append({
                    "NORAD ID": line1.split()[1],
                    "ìœ„ì„±ëª…ì¹­": name,
                    "ì˜ˆìƒ ë‚™í•˜ ìœ„ë„": round(lat, 2),
                    "ì˜ˆìƒ ë‚™í•˜ ê²½ë„": round(lon, 2),
                    "ì˜ˆìƒ ë‚™í•˜ ì‹œê°„": dt.strftime('%Y-%m-%d %H:%M:%S UTC')
                })
                break

        # decay term ê¸°ë°˜ ê¶¤ë„ ë¶•ê´´ í›„ë³´
        decay_term_str = line1[53:61].strip()
        if decay_term_str and float(decay_term_str) >= 0.0001:
            decaying_objects.append(name)

    except:
        continue

# ğŸ“ ì„œìš¸ ê¸°ì¤€ ì§€ì •ë²”ìœ„ ë‚´ ì˜ˆìƒ ìš°ì£¼ë‚™í•˜ë¬¼ì²´
st.subheader("ğŸ“ ì„œìš¸ ê¸°ì¤€ ì§€ì •ë²”ìœ„ ë‚´ ì˜ˆìƒ ìš°ì£¼ë‚™í•˜ë¬¼ì²´")
if seoul_objects:
    seoul_df = pd.DataFrame(seoul_objects)[["NORAD ID", "ìœ„ì„±ëª…ì¹­", "ì˜ˆìƒ ë‚™í•˜ ìœ„ë„", "ì˜ˆìƒ ë‚™í•˜ ê²½ë„", "ì˜ˆìƒ ë‚™í•˜ ì‹œê°„"]]
    st.dataframe(seoul_df, use_container_width=True)
    csv = seoul_df.to_csv(index=False).encode('utf-8')
    st.download_button("ğŸ“‚ ë‚™í•˜ì˜ˆìƒ ìš°ì£¼ë¬¼ì²´ CSV ë‹¤ìš´ë¡œë“œ", data=csv, file_name="seoul_decay_objects.csv", mime='text/csv')
else:
    st.info("âœ… í•´ë‹¹ ë°˜ê²½ ë‚´ ë‚™í•˜ì˜ˆìƒ ë¬¼ì²´ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ğŸ“… 180ì¼ ì´ë‚´ ê¶¤ë„ ë¶•ê´´ ì˜ˆìƒ ìš°ì£¼ë¬¼ì²´
st.subheader("ğŸ“… 180ì¼ ì´ë‚´ ì˜ˆìƒ ìš°ì£¼ ë‚™í•˜ë¬¼ì²´")
if decaying_objects:
    for name in decaying_objects:
        st.markdown(f"- ğŸ›°ï¸ **{name}** | TLE decay term â‰¥ 0.0001")
else:
    st.info("ğŸ“­ í˜„ì¬ 180ì¼ ì´ë‚´ ê¶¤ë„ ë¶•ê´´ ì˜ˆìƒ ìš°ì£¼ë¬¼ì²´ê°€ ì—†ìŠµë‹ˆë‹¤.")
